{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_-aVwOsW2Y4",
        "outputId": "8342ee2d-40c5-4d13-8492-80f17885cbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XqjpPOxEW6Vn",
        "outputId": "613680d6-d165-42c0-a722-59d5c09ecd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection**"
      ],
      "metadata": {
        "id": "bDIOBxSoB7tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Setup Reddit API access\n",
        "print(\"Initializing Reddit connection...\")\n",
        "\n",
        "try:\n",
        "    # Configure the Reddit instance\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=\"Q3b_fvUxT7upIi1msSisrw\",\n",
        "        client_secret=\"zJyEmWdd1yYV2zVDfVyHCNpbLM2DfQ\",\n",
        "        user_agent=\"script:TeslaSolarScraper:v1.0 by u/Wonderful_Check_2951\",\n",
        "        redirect_uri=\"http://localhost:8080\"\n",
        "    )\n",
        "\n",
        "    # Set to read-only mode\n",
        "    reddit.read_only = True\n",
        "\n",
        "    print(\"Connected to Reddit API in read-only mode\")\n",
        "\n",
        "    # Test connection by getting info about the subreddit\n",
        "    subreddit = reddit.subreddit(\"TeslaSolar\")\n",
        "    print(f\"Accessing r/{subreddit.display_name}\")\n",
        "\n",
        "    # Fetch posts\n",
        "    print(\"Retrieving posts...\")\n",
        "    posts = []\n",
        "    count = 0\n",
        "\n",
        "    for post in subreddit.top(limit=100):\n",
        "        count += 1\n",
        "        # Convert Unix timestamp to human-readable date\n",
        "        readable_date = datetime.fromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        posts.append({\n",
        "            'date': readable_date,  # Using the formatted date string\n",
        "            'unix_timestamp': post.created_utc,  # Keep the original timestamp for reference\n",
        "            'title': post.title,\n",
        "            'text': post.selftext,\n",
        "            'score': post.score,\n",
        "            'url': post.url\n",
        "        })\n",
        "\n",
        "        if count % 10 == 0:\n",
        "            print(f\"Retrieved {count} posts...\")\n",
        "        time.sleep(2)  # Be gentle with the API\n",
        "\n",
        "    # Create DataFrame and save to CSV\n",
        "    if posts:\n",
        "        df = pd.DataFrame(posts)\n",
        "        df.to_csv('tesla_solar_reddit_posts.csv', index=False)\n",
        "        print(f\"Successfully saved {len(posts)} posts to CSV file.\")\n",
        "    else:\n",
        "        print(\"No posts were retrieved.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred: {type(e).__name__}: {e}\")"
      ],
      "metadata": {
        "id": "igsshRDPB6r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "_5YLPHLmB-eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"    \""
      ],
      "metadata": {
        "id": "wM6rHsuBXPl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your original posts\n",
        "df = pd.read_csv('/content/drive/MyDrive/Project Tesla/tesla_solar_reddit_posts.csv')\n",
        "\n",
        "# Fill missing title/text safely\n",
        "df['title'] = df['title'].fillna('')\n",
        "df['text'] = df['text'].fillna('')\n",
        "\n",
        "# Combine title and text into one field for analysis\n",
        "df['content'] = df['title'] + ' ' + df['text']\n",
        "\n",
        "# Optional: Remove very short posts\n",
        "df = df[df['content'].str.len() > 10]\n",
        "\n",
        "# Reset index\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Total posts after cleaning: {len(df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_egeB0J-Xb_V",
        "outputId": "0bd5dc52-e44f-4c25-802f-65e978517426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total posts after cleaning: 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization function\n",
        "def summarize_post(post_text):\n",
        "    prompt = f\"Summarize the following Reddit post into 1-2 sentences, highlighting the main issue or event:\\n\\n{post_text}\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful summarizer.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=60\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Create summary column only if it doesn't exist yet\n",
        "if 'summary' not in df.columns:\n",
        "    df['summary'] = df['content'].apply(summarize_post)"
      ],
      "metadata": {
        "id": "g7gjqrC4wahj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(existing_labels, post_text, similarity_threshold=70):\n",
        "    if not existing_labels:\n",
        "        return f\"\"\"\n",
        "You are a smart assistant for categorizing Reddit posts related to Tesla Solar products.\n",
        "\n",
        "Task:\n",
        "- Suggest a new topic label for the following post.\n",
        "- The label must be specific, informative, and actionable.\n",
        "- It should clearly summarize the main issue or event in 3 to 7 words.\n",
        "- Avoid generic labels like \"Solar Discussion\" or \"Update.\"\n",
        "- Focus on the real problem, experience, or event being discussed.\n",
        "\n",
        "Post:\n",
        "\"{post_text}\"\n",
        "\n",
        "Respond ONLY in the format:\n",
        "New Label: <your label>\n",
        "\"\"\"\n",
        "\n",
        "    label_list = '\\n'.join([f\"- {label}: {desc}\" for label, desc in existing_labels.items()])\n",
        "\n",
        "    return f\"\"\"\n",
        "You are a smart assistant for categorizing Reddit posts related to Tesla Solar products.\n",
        "\n",
        "Existing Labels:\n",
        "{label_list}\n",
        "\n",
        "New Post:\n",
        "\"{post_text}\"\n",
        "\n",
        "Task:\n",
        "- If any existing label matches the post meaning with ≥ {similarity_threshold}% similarity, pick that label.\n",
        "- If no existing label matches well enough, suggest a new label.\n",
        "- The label must be specific, informative, and actionable.\n",
        "- It should clearly summarize the main issue or event in 3 to 7 words.\n",
        "- Avoid vague labels like \"Feedback\" or \"Update.\"\n",
        "- Focus on the real problem, experience, or event being discussed.\n",
        "\n",
        "Respond ONLY in the format:\n",
        "Existing Label: <label name>\n",
        "or\n",
        "New Label: <your new label suggestion>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p2fkq1iGXfVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send prompt to GPT and get clean answer\n",
        "def ask_llm(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=50  # short focused output\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()"
      ],
      "metadata": {
        "id": "2hqqX2dQXhg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "labels = {}  # Store existing labels\n",
        "assigned_labels = []  # Store assigned label for each post\n",
        "\n",
        "# Loop through posts\n",
        "for idx, post_text in enumerate(df['content']):\n",
        "    prompt = create_prompt(labels, post_text)\n",
        "    response = ask_llm(prompt)\n",
        "\n",
        "    if response.startswith(\"Existing Label:\"):\n",
        "        label_name = response.replace(\"Existing Label:\", \"\").strip()\n",
        "    elif response.startswith(\"New Label:\"):\n",
        "        label_name = response.replace(\"New Label:\", \"\").strip()\n",
        "        labels[label_name] = post_text  # Save first example post as description\n",
        "    else:\n",
        "        label_name = f\"Label_{idx}\"\n",
        "        labels[label_name] = post_text\n",
        "\n",
        "    assigned_labels.append(label_name)\n",
        "\n",
        "# Add labels to DataFrame\n",
        "df['category'] = assigned_labels\n",
        "\n",
        "print(\"Posts have been labeled!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_waK_GNuXlK_",
        "outputId": "f74e3609-b756-40f9-b285-1c3c39b11bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posts have been labeled!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save labeled posts to new CSV\n",
        "df.to_csv('/content/drive/MyDrive/Project Tesla/tesla_solar_reddit_posts_labeled.csv', index=False)\n",
        "\n",
        "print(\"Final CSV saved with 'category' column!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbxukO-3Xq2x",
        "outputId": "72433da1-e4fb-433c-fde8-2487c50fc677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final CSV saved with 'category' column!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_grouping = {\n",
        "    \"Tesla Solar System Downtime Woes\": \"System Performance Problems\",\n",
        "    \"Powerwall Delay Frustration\": \"Powerwall Delivery/Installation Delays\",\n",
        "    \"Positive Tesla Energy Bill Experience\": \"Positive Customer Experiences\",\n",
        "    \"Tesla Solar Service Delays\": \"Customer Service Problems\",\n",
        "    \"Roof Damage Dispute with Tesla\": \"Roof Quality Issues\",\n",
        "    \"Powerwall Delivery Delay Frustration\": \"Powerwall Delivery/Installation Delays\",\n",
        "    \"Powerwall Installation Delay Frustration\": \"Powerwall Delivery/Installation Delays\",\n",
        "    \"Tesla Solar System Performance Issues\": \"System Performance Problems\",\n",
        "    \"Tesla Solar System Performance Concerns\": \"System Performance Problems\",\n",
        "    \"Tesla Solar Customer Service Frustrations\": \"Customer Service Problems\",\n",
        "    \"Solar Roof Installation Completion\": \"Positive Customer Experiences\",\n",
        "    \"Tesla Solar System Reliability Concerns\": \"System Performance Problems\",\n",
        "    \"Hurricane Resilience with Tesla Solar\": \"Positive Customer Experiences\",\n",
        "    \"Solar System Performance Concerns\": \"System Performance Problems\",\n",
        "    \"Solar System Installation Delay Frustration\": \"Installation Delays\",\n",
        "    \"Tesla Solar Roof Leak Issue\": \"Roof Quality Issues\",\n",
        "    \"Solar Roof Material Arrival Update\": \"Installation Progress Updates\",\n",
        "    \"Tesla Solar System Installation Delays\": \"Installation Delays\"\n",
        "}\n",
        "\n",
        "df['dashboard_category'] = df['category'].map(label_grouping).fillna(df['category'])"
      ],
      "metadata": {
        "id": "4a0DRXjeX5Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save labeled posts to new CSV\n",
        "df.to_csv('/content/drive/MyDrive/Project Tesla/tesla_solar_reddit_posts_GroupLabeled.csv', index=False)\n",
        "\n",
        "print(\"Final CSV saved with 'category' column!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzrJUCGmakbU",
        "outputId": "329f53b2-0c66-4fa8-eb6d-24ccf2ae561d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final CSV saved with 'category' column!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jcV8wclabeFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}